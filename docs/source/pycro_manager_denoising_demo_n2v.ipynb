{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "pycro_manager_denoising_demo_n2v.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk-GvtlVYJln",
        "colab_type": "text"
      },
      "source": [
        "<hr style=\"height:2px;\">\n",
        "\n",
        "# Demo: Denoising of 2D cell images\n",
        "\n",
        "Copy this notebook into a directory in your Google drive.  \n",
        "\n",
        "In this tutorial we will create a deep learning denoising model trained on data aquired by pycromanager on your microscope. We will then used this denoising model to denoise images collected by Pycro-Manager in real time.   \n",
        "\n",
        "We will be running image aquisition and inference locally, and train on a Google Colab GPU instance, though if you have a fairly powerful GPU locally feel free to train locally.\n",
        "\n",
        "The deep learning model used in this tutorial is N2V (https://github.com/juglab/n2v), which allows us to create a denoising algorithm without groud truth images by training on noisy images without clean targets. Check out how it works at https://arxiv.org/pdf/1811.10980.pdf.\n",
        "\n",
        "Please install [Pycro-Manager](https://pycro-manager.readthedocs.io/en/latest/setup.html) locally before running this Colab notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHs5GbfqZ4-s",
        "colab_type": "text"
      },
      "source": [
        "<hr style=\"height:2px;\">\n",
        "\n",
        "# Part 1: Connect to a local runtime\n",
        "\n",
        "If you have not yet, install Pycro-Manager:   \n",
        "```\n",
        "pip install pycromanager\n",
        "```\n",
        "\n",
        "Open a terminal locally and run:\n",
        "```\n",
        "pip install --upgrade jupyter_http_over_ws>=0.0.7 && \\\n",
        "```\n",
        "\n",
        "Create a local jupyter runtime:\n",
        "```\n",
        "jupyter notebook --no-browser\n",
        "```\n",
        "Copy the backend URL. It should look something like http://localhost:8888/?token=SomthingElse.  \n",
        "In the top right of this notebook click \"Connect\" then \"Connect to local runtime\". Enter your backend URL.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSsbKOGiDZuI",
        "colab_type": "text"
      },
      "source": [
        "<hr style=\"height:2px;\">\n",
        "\n",
        "# Part 2: Collecting Training Images\n",
        "\n",
        "First verify you have a working installation of [Pycro-Manager](https://pycro-manager.readthedocs.io/en/latest/setup.html). Open Micro-Manager, select tools-options, and check the box that says Run server on port 4827 (you only need to do this once). Run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qoz8ovU4DgP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pycromanager import Bridge\n",
        "bridge = Bridge()\n",
        "bridge.get_core()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8py8Ym6oD7h9",
        "colab_type": "text"
      },
      "source": [
        "The output should look something like:   \n",
        "```\n",
        "Out[1]: JavaObjectShadow for : mmcorej.CMMCore\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8nCu7TKdD1W",
        "colab_type": "text"
      },
      "source": [
        "It is important that the images we use to create the denoising use the same camera and imaging settings (gain, em-gain, read-out-parameters,...) as in your experiments.  \n",
        "We recommend that you aquire 3-10 images. If your camera is higher resolution, or if you are not running this notebook with a GPU, we recommend using fewer images. In this tutorial we will be capturing images of a single scene though you may gain improved performance from capturing different samples and fields of view."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k5-m77LYJlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlS1SM2CYJmd",
        "colab_type": "text"
      },
      "source": [
        "## Aquisition\n",
        "\n",
        "Adjust your microscope to thge imaging settings (gain, em-gain, read-out-parameters,...) you plan to use in your experiments. Stage your sample.We will now collect the images and store them in a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL9wd8a5hfMU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quantity = 6 # Adjust to number of images you would like to collect\n",
        "dataRaw = []\n",
        "\n",
        "while quantity >= 0: # Includes 1 test image\n",
        "    \n",
        "    # The micro-manager core exposes several mechanisms foor acquiring images. In order to  not interfere\n",
        "    # with other pycromanager functionality, this is the one that should be used\n",
        "    core.snap_image()\n",
        "    tagged_image = core.get_tagged_image()\n",
        "    # If using micro-manager multi-camera adapter, use core.getTaggedImage(i), where i is the camera index\n",
        "    \n",
        "    # pixels by default come out as a 1D array. We can reshape them into an image\n",
        "    pixels = np.reshape(tagged_image.pix, newshape=[tagged_image.tags['Height'], tagged_image.tags['Width']])\n",
        "    dataRaw.append(pixels)\n",
        "\n",
        "dataRaw = np.array(dataRaw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQ4I2_PXyUAs",
        "colab_type": "text"
      },
      "source": [
        "Let's save our data in a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLQuyEj9yXxw",
        "colab_type": "code",
        "outputId": "c564b12b-b597-4580-a2b4-fa266d32f56e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "np.save(dataRaw.npy, dataRaw)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2936aabac552>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataRaw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnpy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataRaw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BghrcoaCpkJ5",
        "colab_type": "text"
      },
      "source": [
        "<hr style=\"height:2px;\">\n",
        "\n",
        "# Part 3: Creating the Model\n",
        "\n",
        "If you have a Nvidia GPU and would like to train the model locally, feel free to skip to the next block of code. Else we would like to connect to a Colab runtime to utilize a free GPU instance.   \n",
        "\n",
        "We want to enable GPU acceleration to speed up training. Under 'Runtime' dropdown in the left top bar, select 'change runtime type' and select 'GPU'.   \n",
        "\n",
        "First disconnect from the local runtime using the dropdown in the top right, and switch the runtime  back to 'hosted'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RagzNkkls1Jm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "9544ce87-9d74-4d55-b065-45645e09cb5e"
      },
      "source": [
        "% tensorflow_version 1.x # CSBDeep is built on Tensorflow v1, if running locally run 'pip install tensorflow-gpu'\n",
        "% nvidia-smi # Check that we are connected to a GPU\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.x # CSBDeep is built on Tensorflow v1, if running locally run 'pip install tensorflow-gpu'`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%nvidia` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieAgRzhIsQkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from n2v.models import N2VConfig, N2V\n",
        "from n2v.internals.N2V_DataGenerator import N2V_DataGenerator\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.image import imread, imsave\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tYBJ86MsPNX",
        "colab_type": "text"
      },
      "source": [
        "Upload `dataRaw.npy` from the directory you started your local runtime to the Colab notebook directory using the 'file' button on the left side-menu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hst_5ut9rVjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imgs = np.load('/content/dataRaw.npy')\n",
        "testImg = imgs[0]\n",
        "imgs = [1:]\n",
        "# # If on local runtime use:\n",
        "# imgs = np.load('dataRaw.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-Z_k9nnuPEe",
        "colab_type": "text"
      },
      "source": [
        "Check that we can view our images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE2ktf73uN2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(14,7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imgs[0], cmap='magma')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imgs[1], cmap='magma')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnRxhuuJwoKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "patches = datagen.generate_patches_from_list(imgs, shape=(64,64))\n",
        "import random\n",
        "random.shuffle(patches)\n",
        "divide = int(len(patches)/8)\n",
        "train_patches = patches[divide:]\n",
        "val_patches = patches[:divide]\n",
        "print(len(train_patches))\n",
        "print(len(val_patches))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lclT96evyOmV",
        "colab_type": "text"
      },
      "source": [
        "Let's look at one of our training and validation patches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXxbSX6yyLtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(14,7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(train_patches[0,...,0], cmap='magma')\n",
        "plt.title('Training Patch');\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(val_patches[0,...,0], cmap='magma')\n",
        "plt.title('Validation Patch');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8kEQ1ItHyvUc",
        "colab_type": "text"
      },
      "source": [
        "Let's configure our model. We very strongly recommend that you not train for more than 120 epochs on Colab as the system will time out after 12 hours. Make sure not to close your browser or after 90 minutes this notebook's data will be erased."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJJ5HwOnyv6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = N2VConfig(train_patches, unet_n_depth=3, unet_kern_size=3, train_steps_per_epoch=300, train_epochs=80, \n",
        "                   train_learning_rate=0.0005, train_loss='mse', batch_norm=True, train_batch_size=128, \n",
        "                   n2v_perc_pix=0.198, n2v_patch_shape=(64, 64), unet_n_first = 96, \n",
        "                   unet_residual = True, n2v_manipulator='uniform_withCP')\n",
        "vars(config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4y5gKKt51H3v",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive. We will save our model to a folder in Drive to not loose it when we close this Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bf4XM251I1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLCSOZLDzZME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'n2v_fluorescence_microscopy'\n",
        "model_dir = '/content/gdrive/My Drive/denoising_model'\n",
        "# We are now creating our network model.\n",
        "model = N2V(config=config, name=model_name, basedir=basedir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAtRm1Dczcro",
        "colab_type": "text"
      },
      "source": [
        "Time to train our model. Make sure not to close this notebook during training if you are using a hosted runtime. This may take a while, around 11 hours for 100 epochs with the provided settings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANmwZIIZzoZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.train(train_patches, val_patches)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XTENRnK0Yzm",
        "colab_type": "text"
      },
      "source": [
        "Let's test our fresh model on an image we collected earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hMWoT8g0ZBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(testImg, axes='YX')\n",
        "plt.figure(figsize=(14,7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img, cmap='magma')\n",
        "plt.title('Raw Image');\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(pred, cmap='magma')\n",
        "plt.title('Denoised');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9gfmMYZ2ArK",
        "colab_type": "text"
      },
      "source": [
        "<hr style=\"height:2px;\">\n",
        "\n",
        "# Part 4: Testing our Model\n",
        "Now let's test using our algorithm and denoise images collected in real time using Pycro-Manager!   \n",
        "\n",
        "First, start and reconnect to a local runtime. Download the folder `denoising_model` from your Google Drive to the current working directory of your local runtime.   \n",
        "\n",
        "Let's load our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlYbrBJP3JBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from n2v.models import N2VConfig, N2V\n",
        "from pycromanager import Bridge, Acquisition, multi_d_acquisition_events\n",
        "bridge = Bridge()\n",
        "bridge.get_core()\n",
        "\n",
        "model_name = 'n2v_fluorescence_microscopy'\n",
        "basedir = './'\n",
        "# We are now creating our network model.\n",
        "model = N2V(config=None, name=model_name, basedir=basedir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AESOfKnTgmC",
        "colab_type": "text"
      },
      "source": [
        "Create a Pycro-Manager [image processor](https://pycro-manager.readthedocs.io/en/latest/img_processors.html) that applies the deep learning model we created to images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGA-evviT7kI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def img_process_fn(image, metadata):\n",
        "  metadata['a_new_metadata_key'] = 'a new value'\n",
        "  image = model.predict(img, axes='YX')\n",
        "  plt.imshow(image, cmap='magma')\n",
        "\n",
        "  # propogate the image and metadata to the default viewer and saving classes\n",
        "  return image, metadata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dD1XKPPZ-3O",
        "colab_type": "text"
      },
      "source": [
        "Let's aquire an image!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5avXUswTQAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory_to_save_images = '/aquisitions_tmp'\n",
        "if __name__ == '__main__': #this is important, don't forget it\n",
        "  with Acquisition(directory=directory_to_save_images, name='acquisition_1', image_process_fn=img_process_fn) as acq:\n",
        "    acq.aquire()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxbsxrfYaCeX",
        "colab_type": "text"
      },
      "source": [
        "Let's view our denoised image!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwKVo7WWayYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = imread('/aquisitions_tmp/acquisition_1.png')\n",
        "plt.imshow(img, cmap='magma')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}